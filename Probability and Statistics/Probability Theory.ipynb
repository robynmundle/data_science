{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f16ed41-25c5-49c5-960b-d07a4b415a33",
   "metadata": {},
   "source": [
    "# Probability Theory\n",
    "Probability theory is a branch of mathematics concerned with probability. Although there are several different probability interpretations, probability theory treats the concept in a rigorous mathematical manner by expressing it through a set of axioms.\n",
    "\n",
    "Probability is a ratio of the number of probabilities that meet the given condition to the number of equally likely possibilities (i.e. P(heads on coin toss) = 1 chance of heads / 2 options (heads or tails) = ½. In probability theory, an event is a set of outcomes of an experiment to which a probability is assigned. If E represents an event, then P(E) represents the probability that E will occur. A situation where E might happen (success) or might not happen (failure) is called a trial. This event can be anything like tossing a coin, rolling a die or pulling a colored ball out of a bag. In these examples the outcome of the event is random, so the variable that represents the outcome of these events is called a random variable.\n",
    "- The **empirical probability** of an event is given by number of times the event occurs divided by the total number of incidents observed. If forntrials and we observe ssuccesses, the probability of success is s/n. In the above example. any sequence of coin tosses may have more or less than exactly 50% heads.\n",
    "- **Theoretical probability** on the other hand is given by the number of ways the particular event can occur divided by the total number of possible outcomes. So a head can occur once and possible outcomes are two (head, tail). The true (theoretical) probability of a head is 1/2.\n",
    "- **Joint Probability** is the probability of events A and B denoted by P(A and B) or P(A ∩ B) is the probability that events A and B both occur. P(A ∩ B) = P(A). P(B) . This only applies if Aand B are independent, which means that if A occurred, that doesn’t change the probability of B, vice versa. The probability of the intersection of A and B may be written P(A ∩ B). *Example: What is the probability that a drawn card is a red four? There are two red fours in a deck of 52, the 4 of hearts and the 4 of diamonds, therefore P(four and red) = 2/52=1/26.*\n",
    "- **Conditional Probability** suggests A and B are not independent, because if A occurred, the probability of B is higher. When A and B are not independent, it is often useful to compute the conditional probabiliuty, P(A|B), which is the probability of A given that B occurred: \n",
    "    - P(A|B) = P(A ∩ B)/ P(B) or similarly,  P(B|A) = P(A ∩ B)/ P(A) . We can write the joint probability of as A and B as P(A ∩ B)= p(A).P(B|A), which means : *“The chance of both things happening is the chance that the first one happens, and then the second one given the first happened.”*\n",
    "    - https://youtu.be/bgCMjHzXTXs\n",
    "    - https://youtu.be/ES9HFNDu4Bs\n",
    "    - https://mithunmanohar.medium.com/machine-learning-101-what-the-is-a-conditional-probability-f0f9a9ec6cda\n",
    "    - https://seeing-theory.brown.edu/basic-probability/index.html#section1\n",
    "- **Marginal Probability** is the probability of an event occurring P(A) . We can think of it as an unconditional probability. It is not conditioned by another event. *Example: The probability that a drawn card is red P(red) = 0.5.*\n",
    "\n",
    "## Probability Distribution\n",
    "Probability distributions describe the dispersion of the values of a random variable. Consequently, the kind of variable determines the type of probability distribution. For a single random variable, statisticians divide distributions into the following two types:\n",
    "- Probability mass functions for discrete variables (PMF)\n",
    "- Probability density functions for continuous variables (PDF)\n",
    "\n",
    "## Data Types\n",
    "- Discrete data can take only specified values i.e. roll of a dice is 1, 2, 3, 4, 5, or 6 not 1.5\n",
    "- Continuous data can take any value within a given range, finite or infinite i.e. a person’s height/weight\n",
    "\n",
    "Online Resources:\n",
    "* https://towardsdatascience.com/machine-learning-probability-statistics-f830f8c09326\n",
    "* https://youtu.be/uzkc-qNVoOk\n",
    "\n",
    "## Bayes Theorem\n",
    "A relationship between the conditional probabilities of two events. For example: selling ice cream on a hot sunny day, BT uses prior knowledge of likelihood selling on other days (rainy, windy, snowy, etc.)\t\n",
    "\n",
    "<img src='images/bayes.png'>\n",
    "\n",
    "* where H and E are events, P(H|E) is the conditional probability that event H occurs given E occurred\n",
    "* Probability P(H) is basically frequency analysis; given our prior data what is the probability of it occurring\n",
    "* P(E|H) is called the likelihood, the probability that the evidence is correct, given info from freq. analysis.\n",
    "* P(E) is the probability that the actual evidence is true.\n",
    "\n",
    "In example: H represents event selling ice cream. E is the event of weather. P(H) is the marginal probability of prior sales of ice cream regardless of weather.\n",
    "\n",
    "Online Resources:\n",
    "* https://www.mathsisfun.com/data/bayes-theorem.html\n",
    "* https://youtu.be/HZGCoVF3YvM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
